{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание проекта\n",
    "Интернет-магазину необходимо автоматически выделять токсичные/негативные комментарии и отправлять их на модерацию. \n",
    "Для этого нужно обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Метрика качества: *F1* не меньше 0.75. \n",
    "\n",
    "### План проекта\n",
    "\n",
    "1. Загрузить и подготовить данные.\n",
    "2. Обучить разные модели. \n",
    "3. Сделать выводы.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ознакомимся с дататсетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text  toxic\n",
      "0       Explanation\\nWhy the edits made under my usern...      0\n",
      "1       D'aww! He matches this background colour I'm s...      0\n",
      "2       Hey man, I'm really not trying to edit war. It...      0\n",
      "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
      "4       You, sir, are my hero. Any chance you remember...      0\n",
      "...                                                   ...    ...\n",
      "159566  \":::::And for the second time of asking, when ...      0\n",
      "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
      "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
      "159569  And it looks like it was actually you who put ...      0\n",
      "159570  \"\\nAnd ... I really don't think you understand...      0\n",
      "\n",
      "[159571 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comments = pd.read_csv('//datasets/toxic_comments.csv')\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143346\n",
      "1     16225\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(comments['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что целевой признак содержится в столбце toxic, комментарии в столбце text. Создадим корпус текстов из каждого комментария."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(comments['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем формулу для лемматизации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    s = nltk.word_tokenize(text)\n",
    "    string = ' '.join([lemmatizer.lemmatize(w) for w in s])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем формулу для очистки текста от регулярных выражений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text_cleared = re.sub(r'[^a-zA-Z\\']', ' ', text)\n",
    "    text_cleared = \" \".join(text_cleared.split())\n",
    "    return text_cleared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем корпус при помощи данных формул"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 569 ms, total: 2min 10s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(comments['text'])):\n",
    "    #print(i)\n",
    "    corpus[i] = lemmatize(clear_text(corpus[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They were n't vandalism just closure on some GAs after I voted at New York Dolls FAC And please do n't remove the template from the talk page since I 'm retired now\n"
     ]
    }
   ],
   "source": [
    "#для примера выведем первый текст корпуса\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "159566    0\n",
      "159567    0\n",
      "159568    0\n",
      "159569    0\n",
      "159570    0\n",
      "Name: toxic, Length: 159571, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target = comments['toxic']\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на обучающую и тестовую выборки. На тест отведем 25% генеральной совокупности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "corpus_train, corpus_test, target_train, target_test = train_test_split(corpus, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для очистки текста от не несущих эмоциональную окраску местоимений и предлогов загрузим стопслова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf = count_tf_idf.fit(corpus_train)\n",
    "tf_idf_train = count_tf_idf.transform(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Мы лемматизировали текст, очистили от ненужных символов и стопслов. Векторизовали корпус текстов, разделили на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем логистическую регрессию, решающее дерево, случайный лес.\n",
    "Начнем с обучения логистической регрессии. Качество модели будем оценивать с помощью кросс-валидации по метрике f1. Предварительно сбалансируем классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=12345, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя оценка качества модели: 0.7428330163523045\n"
     ]
    }
   ],
   "source": [
    "final_score = cross_val_score(model, tf_idf_train, target_train, cv=3, scoring='f1')\n",
    "final_score = final_score.sum() / len(final_score)\n",
    "print('Средняя оценка качества модели:', final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "state=12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем Древо решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.32\n",
      "F1 score: 0.37\n",
      "F1 score: 0.43\n",
      "F1 score: 0.47\n",
      "F1 score: 0.50\n",
      "F1 score: 0.50\n",
      "F1 score: 0.53\n",
      "F1 score: 0.54\n",
      "F1 score: 0.37\n",
      "\n",
      "Наибольший F1 score = 0.54 при значении n_estimators = 3 и max_depth = 9\n"
     ]
    }
   ],
   "source": [
    "f1_best = 0\n",
    "#estim_best = 0\n",
    "depth_best = 0\n",
    "\n",
    "for depth in range(2, 11):\n",
    "    model = DecisionTreeClassifier(random_state = state, max_depth = depth, class_weight='balanced')\n",
    "    f1_score = cross_val_score(model, tf_idf_train, target_train, cv=3, scoring='f1')\n",
    "    f1_score = f1_score.sum() / len(f1_score)\n",
    "    print('F1 score: {:.2f}'.format(f1_score))\n",
    "    if f1_score>f1_best:\n",
    "        f1_best=f1_score\n",
    "        #estim_best=estim\n",
    "        depth_best=depth\n",
    "\n",
    "print('')\n",
    "print('Наибольший F1 score = {:.2f} при значении n_estimators = {} и max_depth = {}'.format(f1_best, 3, depth_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем случайный лес при наилучшей глубине для решающего дерева (9), при количестве деревьев в диапазоне от 1 до 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.20\n",
      "F1 score: 0.21\n",
      "F1 score: 0.22\n",
      "F1 score: 0.23\n",
      "F1 score: 0.24\n",
      "F1 score: 0.25\n",
      "F1 score: 0.25\n",
      "F1 score: 0.26\n",
      "F1 score: 0.27\n",
      "F1 score: 0.27\n",
      "\n",
      "Наибольший F1 score = 0.27 при значении n_estimators = 10 и max_depth = 9\n"
     ]
    }
   ],
   "source": [
    "f1_best = 0\n",
    "estim_best = 0\n",
    "#depth_best = 0\n",
    "\n",
    "for estim in range(1, 11):\n",
    "    model = RandomForestClassifier(random_state = state, n_estimators = estim, max_depth = 9, class_weight='balanced')\n",
    "    f1_score = cross_val_score(model, tf_idf_train, target_train, cv=3, scoring='f1')\n",
    "    f1_score = f1_score.sum() / len(f1_score)\n",
    "    print('F1 score: {:.2f}'.format(f1_score))\n",
    "    if f1_score>f1_best:\n",
    "        f1_best=f1_score\n",
    "        estim_best=estim\n",
    "        #depth_best=depth\n",
    "\n",
    "print('')\n",
    "print('Наибольший F1 score = {:.2f} при значении n_estimators = {} и max_depth = {}'.format(f1_best, estim_best, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем лучшие модели на тестовой выборке. Начнем с логичтической регресси"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7503\n",
      "CPU times: user 8.66 s, sys: 5.35 s, total: 14 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import f1_score\n",
    "model = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "model.fit(tf_idf_train, target_train)\n",
    "prediction = model.predict(tf_idf_test)\n",
    "print('F1 score: {:.4f}'.format(f1_score(target_test, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.5325\n",
      "CPU times: user 8.33 s, sys: 8.36 ms, total: 8.34 s\n",
      "Wall time: 8.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = DecisionTreeClassifier(random_state = state, max_depth = 9, class_weight='balanced')\n",
    "model.fit(tf_idf_train, target_train)\n",
    "prediction = model.predict(tf_idf_test)\n",
    "print('F1 score: {:.4f}'.format(f1_score(target_test, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.2952\n",
      "CPU times: user 798 ms, sys: 3.78 ms, total: 802 ms\n",
      "Wall time: 812 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(random_state = state, n_estimators = 10, max_depth = 9, class_weight='balanced')\n",
    "model.fit(tf_idf_train, target_train)\n",
    "prediction = model.predict(tf_idf_test)\n",
    "print('F1 score: {:.4f}'.format(f1_score(target_test, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуемое качество метрики достигнуто при использовании модели машинного обучения - логистическая регрессия, используем ее для решения поставленной бизнес-задачи."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
